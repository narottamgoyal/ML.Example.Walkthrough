{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Length:  625\n",
      "Dataset Shape:  (625, 5)\n",
      "Dataset:\n",
      "    0  1  2  3  4\n",
      "0  B  1  1  1  1\n",
      "1  R  1  1  1  2\n",
      "2  R  1  1  1  3\n",
      "3  R  1  1  1  4\n",
      "4  R  1  1  1  5\n"
     ]
    }
   ],
   "source": [
    "# Function importing Dataset \n",
    "balance_data = pd.read_csv( \n",
    "'https://archive.ics.uci.edu/ml/machine-learning-'+\n",
    "'databases/balance-scale/balance-scale.data', \n",
    "sep= ',', header = None) \n",
    "\n",
    "# Printing the dataswet shape \n",
    "print (\"Dataset Length: \", len(balance_data)) \n",
    "print (\"Dataset Shape: \", balance_data.shape) \n",
    "\n",
    "# Printing the dataset obseravtions \n",
    "print (\"Dataset:\\n\",balance_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'L',\n",
       "       'B', 'R', 'R', 'R', 'B', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'L', 'L',\n",
       "       'B', 'R', 'R', 'L', 'R', 'R', 'R', 'R', 'B', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'L', 'L', 'L',\n",
       "       'B', 'R', 'L', 'B', 'R', 'R', 'R', 'L', 'R', 'R', 'R', 'R', 'B',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'L', 'L', 'L', 'L',\n",
       "       'B', 'L', 'L', 'R', 'R', 'R', 'L', 'R', 'R', 'R', 'R', 'L', 'R',\n",
       "       'R', 'R', 'R', 'B', 'R', 'R', 'R', 'R', 'L', 'B', 'R', 'R', 'R',\n",
       "       'B', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'L', 'L', 'L', 'B', 'R', 'L',\n",
       "       'B', 'R', 'R', 'R', 'L', 'R', 'R', 'R', 'R', 'B', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
       "       'B', 'R', 'R', 'L', 'B', 'R', 'R', 'R', 'L', 'R', 'R', 'R', 'R',\n",
       "       'L', 'R', 'R', 'R', 'R', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
       "       'B', 'R', 'L', 'L', 'R', 'R', 'R', 'L', 'B', 'R', 'R', 'R', 'L',\n",
       "       'R', 'R', 'R', 'R', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
       "       'B', 'L', 'L', 'L', 'R', 'R', 'L', 'L', 'R', 'R', 'R', 'L', 'B',\n",
       "       'R', 'R', 'R', 'L', 'L', 'B', 'R', 'R', 'L', 'R', 'R', 'R', 'R',\n",
       "       'B', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'B', 'R', 'R', 'L',\n",
       "       'B', 'R', 'R', 'R', 'L', 'R', 'R', 'R', 'R', 'L', 'R', 'R', 'R',\n",
       "       'R', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'R', 'L', 'L',\n",
       "       'B', 'R', 'R', 'L', 'L', 'R', 'R', 'R', 'L', 'R', 'R', 'R', 'R',\n",
       "       'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
       "       'B', 'R', 'L', 'L', 'B', 'R', 'R', 'L', 'L', 'R', 'R', 'R', 'L',\n",
       "       'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
       "       'B', 'L', 'L', 'L', 'R', 'R', 'L', 'L', 'B', 'R', 'R', 'L', 'L',\n",
       "       'L', 'B', 'R', 'L', 'B', 'R', 'R', 'R', 'L', 'R', 'R', 'R', 'R',\n",
       "       'B', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'L', 'L', 'L',\n",
       "       'L', 'L', 'L', 'L', 'L', 'B', 'R', 'L', 'L', 'R', 'R', 'R', 'L',\n",
       "       'B', 'R', 'R', 'R', 'L', 'R', 'R', 'R', 'R', 'L', 'L', 'L', 'L',\n",
       "       'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'B', 'R', 'L', 'L',\n",
       "       'B', 'R', 'R', 'L', 'L', 'R', 'R', 'R', 'L', 'L', 'L', 'L', 'L',\n",
       "       'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
       "       'B', 'R', 'L', 'L', 'L', 'R', 'R', 'L', 'L', 'L', 'L', 'L', 'L',\n",
       "       'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
       "       'B', 'L', 'L', 'L', 'B', 'R', 'L', 'L', 'L', 'L', 'B', 'L', 'L',\n",
       "       'R', 'R', 'R', 'L', 'R', 'R', 'R', 'R', 'L', 'R', 'R', 'R', 'R',\n",
       "       'B', 'R', 'R', 'R', 'R', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
       "       'L', 'B', 'L', 'L', 'L', 'R', 'R', 'L', 'L', 'R', 'R', 'R', 'L',\n",
       "       'B', 'R', 'R', 'R', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
       "       'L', 'L', 'L', 'L', 'L', 'B', 'L', 'L', 'L', 'R', 'R', 'L', 'L',\n",
       "       'B', 'R', 'R', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
       "       'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'B', 'L', 'L', 'L',\n",
       "       'B', 'R', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
       "       'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
       "       'B'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balance_data.values[:, 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make predictions \n",
    "def prediction(X_test, clf_object): \n",
    "  \n",
    "    # Predicton on test with giniIndex \n",
    "    y_pred = clf_object.predict(X_test) \n",
    "    print(\"Predicted values:\") \n",
    "    print(y_pred) \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate accuracy \n",
    "def cal_accuracy(y_test, y_pred): \n",
    "      \n",
    "    print(\"Confusion Matrix: \", \n",
    "        confusion_matrix(y_test, y_pred)) \n",
    "      \n",
    "    print (\"Accuracy : \", \n",
    "    accuracy_score(y_test,y_pred)*100) \n",
    "      \n",
    "    print(\"Report : \", \n",
    "    classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split the dataset \n",
    "def splitdataset(balance_data): \n",
    "  \n",
    "    # Separating the target variable \n",
    "    X = balance_data.values[:, 1:5] \n",
    "    Y = balance_data.values[:, 0] \n",
    "  \n",
    "    # Splitting the dataset into train and test \n",
    "    X_train, X_test, y_train, y_test = train_test_split(  \n",
    "    X, Y, test_size = 0.3, random_state = 100) \n",
    "      \n",
    "    return X, Y, X_train, X_test, y_train, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, X_train, X_test, y_train, y_test = splitdataset(balance_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3, min_samples_leaf=5, random_state=100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_using_gini\n",
    "# Creating the classifier object \n",
    "clf_gini = DecisionTreeClassifier(criterion = \"gini\", \n",
    "        random_state = 100,max_depth=3, min_samples_leaf=5) \n",
    "\n",
    "# Performing training \n",
    "clf_gini.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values:\n",
      "['R' 'L' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'R' 'L'\n",
      " 'L' 'R' 'L' 'R' 'L' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'L'\n",
      " 'L' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'R' 'L' 'R'\n",
      " 'R' 'L' 'R' 'R' 'L' 'L' 'R' 'R' 'L' 'L' 'L' 'L' 'L' 'R' 'R' 'L' 'L' 'R'\n",
      " 'R' 'L' 'R' 'L' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'R' 'R' 'L' 'R' 'L'\n",
      " 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'L' 'L' 'L' 'R' 'L' 'R' 'R' 'R' 'R' 'R' 'R'\n",
      " 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'L'\n",
      " 'L' 'L' 'L' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R'\n",
      " 'L' 'L' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'R' 'R'\n",
      " 'L' 'L' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'R' 'R'\n",
      " 'L' 'R' 'R' 'L' 'L' 'R' 'R' 'R']\n"
     ]
    }
   ],
   "source": [
    "# Prediction using gini \n",
    "y_pred_gini = prediction(X_test, clf_gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## https://towardsdatascience.com/reading-a-confusion-matrix-60c4dd232dd4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:  [[ 0  0  0]\n",
      " [ 6 67 19]\n",
      " [ 7 18 71]]\n",
      "Accuracy :  73.40425531914893\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           B       0.00      0.00      0.00         0\n",
      "           L       0.79      0.73      0.76        92\n",
      "           R       0.79      0.74      0.76        96\n",
      "\n",
      "    accuracy                           0.73       188\n",
      "   macro avg       0.53      0.49      0.51       188\n",
      "weighted avg       0.79      0.73      0.76       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cal_accuracy(y_test, y_pred_gini) \n",
    "cal_accuracy(y_pred_gini,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=3, min_samples_leaf=5,\n",
       "                       random_state=100)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tarin_using_entropy\n",
    "# Decision tree with entropy \n",
    "clf_entropy = DecisionTreeClassifier( \n",
    "        criterion = \"entropy\", random_state = 100, \n",
    "        max_depth = 3, min_samples_leaf = 5) \n",
    "\n",
    "# Performing training \n",
    "clf_entropy.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values:\n",
      "['R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'R' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'L'\n",
      " 'L' 'R' 'L' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'L' 'L'\n",
      " 'L' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'L' 'R' 'L' 'L' 'R' 'L' 'L'\n",
      " 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L' 'R' 'L' 'L' 'R' 'L' 'L' 'L' 'R'\n",
      " 'R' 'L' 'R' 'L' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'R' 'R' 'L' 'R' 'L'\n",
      " 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'R' 'R' 'R' 'R' 'R'\n",
      " 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L'\n",
      " 'L' 'L' 'L' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R'\n",
      " 'L' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'R' 'R'\n",
      " 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'L' 'R'\n",
      " 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'R']\n",
      "Confusion Matrix:  [[ 0  6  7]\n",
      " [ 0 63 22]\n",
      " [ 0 20 70]]\n",
      "Accuracy :  70.74468085106383\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           B       0.00      0.00      0.00        13\n",
      "           L       0.71      0.74      0.72        85\n",
      "           R       0.71      0.78      0.74        90\n",
      "\n",
      "    accuracy                           0.71       188\n",
      "   macro avg       0.47      0.51      0.49       188\n",
      "weighted avg       0.66      0.71      0.68       188\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\test_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Prediction using entropy \n",
    "y_pred_entropy = prediction(X_test, clf_entropy) \n",
    "cal_accuracy(y_test, y_pred_entropy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
